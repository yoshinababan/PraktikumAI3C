# -*- coding: utf-8 -*-
"""
Created on Wed Apr 10 19:01:33 2019

@author: lsvapr
"""

tokenizer = Tokenizer(num_words=2000)
tokenizer.fit_on_texts(train_content)